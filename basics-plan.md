## ✅ Day 1 — Python Core + Environment + Logging/Error Basics

```markdown
# Day 1 – Python Core + Environment (Senior AI Engineer Interview Prep)

You are an expert Senior AI Engineer interview coach.

Today is Day 1 of my 15-day compressed GenAI/LLM interview prep plan.

## Your task
For the topics below:
1) Explain each concept clearly (AI/GenAI backend context).
2) Give 2–3 real-world examples (RAG services, model APIs, pipelines).
3) Best practices + pitfalls (robust Python services, large codebases).
4) End with Interview Q&A (5–10 questions + concise strong answers).
5) Any code: beginner-friendly comments + highlight tricky parts.

Use short headings + bullets.

## Topics – cover ALL
### Python fundamentals (refresh)
- Data types: int, float, str, bool
- Collections: list, dict, set, tuple
- Slicing basics
- List/dict comprehensions

### Functions & modules
- Defining functions
- *args, **kwargs
- Modules, packages, imports (absolute vs relative – conceptually)

### Environment & tooling
- venv, pyenv, uv (what/why/when)
- Basic project layout + folder structure
- Config via .env and python-dotenv (what to store where)

### Logging & basic error handling
- logging module basics
- try/except/finally patterns
- When to raise vs return errors (API services)

Deliver one structured explanation.
```

---

## ✅ Day 2 — Python OOP + Dataclasses + Design Exercise

```markdown
# Day 2 – OOP in Python (Interview-Ready for GenAI Systems)

You are an expert Senior AI Engineer interview coach.

Today is Day 2 of my 15-day compressed plan.

## Your task
1) Explain OOP deeply with GenAI codebase examples.
2) Give 2–3 real-world examples (LLM provider interface, RAG pipeline classes, vector DB adapters).
3) Best practices + pitfalls for maintainable/testable OOP.
4) End with Interview Q&A (5–10) + concise answers.
5) Add commented code examples (design intuition + responsibilities).

Use headings + bullets.

## Topics – cover ALL
### Core OOP
- Classes/objects/attributes/methods
- Encapsulation, abstraction
- Inheritance & polymorphism
- Composition vs inheritance (when to prefer composition)

### Python-specific OOP features
- __init__, instance vs class variables
- @staticmethod, @classmethod
- @property
- @dataclass (configs, payloads, tool schemas)

### Dunder methods
- __repr__, __str__, __len__, __eq__ (and why useful)

### Design exercise (must include)
- ModelProvider hierarchy (OpenAI / Anthropic / local LLM)
- RagPipeline (clear responsibilities; where retrieval, rerank, generation live)

Deliver one coherent write-up.
```

---

## ✅ Day 3 — Advanced Python + Testing/Mocks + Clean Architecture & Patterns

```markdown
# Day 3 – Advanced Python + Testing + Clean Architecture (GenAI Codebases)

You are an expert Senior AI Engineer interview coach with strong architecture skills.

Today is Day 3 of my 15-day compressed plan.

## Your task
1) Explain each topic with production GenAI examples.
2) Show how typing/validation/testing reduces outages and regressions.
3) Include best practices + common pitfalls.
4) End with Interview Q&A (5–10) + concise answers.
5) Provide small, heavily-commented code snippets (focus on reasoning).

## Topics – cover ALL
### Type hints & static typing
- typing: List, Dict, Optional, Union, TypedDict
- Why typing helps large AI systems (refactors, fewer runtime bugs)
- mypy (high-level: how teams use it)

### Data validation
- Pydantic basics
- Use cases: API schemas, tool I/O, configuration objects

### Error handling & logging (production)
- Custom exception classes
- logging best practices: levels, structured logs, correlation IDs

### Testing patterns
- pytest fixtures (DB, external API, LLM mock)
- Mocking external services (HTTP, DB, LLM APIs)

### Design patterns + clean architecture for GenAI
- SOLID (high-level mapping to GenAI services)
- Factory (model/provider selection)
- Strategy (retrieval strategies, rerankers)
- Adapter (LLM providers / vector DB wrappers)
- Decorator (logging, caching, auth, retries)
- Facade (simple RagService over complex pipeline)
- Layered architecture: API layer, service layer, data/infra layer
- Example project structure: api/, services/, models/, configs/, workers/, tests/

Deliver one structured explanation.
```

---

## ✅ Day 4 — Async & Concurrency (GenAI Backends)

```markdown
# Day 4 – Async & Concurrency in Python (for GenAI Systems)

You are an expert Senior AI Engineer interview coach.

Today is Day 4 of my 15-day compressed plan.

## Your task
1) Explain async/concurrency clearly with GenAI backend scenarios.
2) Provide 2–3 real-world examples (parallel tool calls, concurrent vector DB queries, background tasks).
3) Best practices + pitfalls (blocking I/O, race conditions, observability).
4) End with Interview Q&A (5–10) + concise answers.
5) Comment code heavily (intuition + flow + edge cases).

## Topics – cover ALL
- Sync vs async I/O (when async matters in GenAI)
- async/await, asyncio
  - event loop basics
  - asyncio.gather, tasks
- Concurrency models
  - threads vs processes vs async I/O
  - concurrent.futures basics
- Pitfalls
  - blocking calls inside async
  - race conditions/shared state
  - debugging + observability patterns for async services

Deliver one structured explanation.
```

---

## ✅ Day 5 — DSA Core I (Arrays/Strings/Hashing/Prefix Sums)

```markdown
# Day 5 – DSA Core I: Arrays, Strings, Hashing & Prefix Sums

You are an expert Senior AI Engineer interview coach with strong DSA skills.

Today is Day 5 of my 15-day compressed plan.

## Your task
1) Teach core patterns in an interview-recall way.
2) Use simple examples + link to real systems (logs, token counts, user events).
3) For each pattern: intuition + time/space + common mistakes.
4) End with 5–10 interview questions + concise correct answers.
5) Any code: clear comments + tricky edge cases.

## Topics – cover ALL
- Big-O basics (quick)
- Arrays/strings
  - traversal, subarrays, substrings
  - prefix sum basics (subarray sum queries)
- Hashing (dict/set)
  - frequency counting
  - two-sum pattern
  - duplicates, anagrams

Deliver one structured explanation.
```

---

## ✅ Day 6 — DSA Core II (Two Pointers / Sliding Window / Stack / Queue)

```markdown
# Day 6 – DSA Core II: Two Pointers, Sliding Window, Stacks & Queues

You are an expert Senior AI Engineer interview coach.

Today is Day 6 of my 15-day compressed plan.

## Your task
1) Explain each pattern with strong intuition and “diagram in words”.
2) Connect to practical problems (stream/log processing, validation).
3) Highlight how to recognize the pattern + pitfalls.
4) End with Interview Q&A (5–10) + short answers.
5) Code must be commented (indexes, boundaries, off-by-one).

## Topics – cover ALL
- Two pointers
  - sorted array problems (2-sum in sorted)
  - inward pointers, move left/right
- Sliding window
  - fixed-size
  - variable-size (longest/shortest substring/subarray with property)
- Stacks & queues
  - basic use cases
  - balanced parentheses
  - monotonic stack (concept) + next greater element

Deliver one structured explanation.
```

---

## ✅ Day 7 — Trees, Graphs, DP Intro + Workflow DAG Linkage

```markdown
# Day 7 – Trees, Graphs, DP Intro + Real-World DAG Linkage

You are an expert Senior AI Engineer interview coach.

Today is Day 7 of my 15-day compressed plan.

## Your task
1) Explain trees/graphs/DP at interview level (pattern recognition + intuition).
2) Show where they appear in real systems (dependency graphs, pipeline DAGs).
3) Provide simple Python examples with comments (DFS/BFS).
4) End with Interview Q&A (5–10) + concise answers.
5) Add a short review checklist for Days 1–6 (key recall bullets).

## Topics – cover ALL
- Trees & graphs
  - DFS and BFS (concept + code)
  - traversals: pre, in, post
- DP basics
  - 0/1 knapsack intuition
  - top-down (memo) vs bottom-up
- Real-world linkage
  - scheduling, dependency graphs, pipeline DAGs (Airflow, LangGraph, etc.)
- Review checklist (Days 1–6)

Deliver one structured explanation.
```

---

## ✅ Day 8 — HTTP + REST API Design + Flask/FastAPI Basics

```markdown
# Day 8 – HTTP + API Design + Flask/FastAPI Basics (LLM Services)

You are an expert Senior AI Engineer interview coach.

Today is Day 8 of my 15-day compressed plan.

## Your task
1) Explain HTTP + REST design with AI/LLM services examples.
2) Provide example endpoints: /chat, /embed, /predict, /health.
3) Cover best practices + pitfalls + versioning.
4) Include Flask vs FastAPI trade-offs and a small illustrative endpoint with validation + auto docs.
5) End with Interview Q&A (5–10) + concise answers.
6) Code: clear comments.

## Topics – cover ALL
### HTTP basics
- methods: GET/POST/PUT/PATCH/DELETE
- status codes (important 2xx/4xx/5xx/3xx)
- headers, query params, path params, body

### REST design
- resource modeling, clean URLs
- idempotency
- versioning (/v1/, /v2/)

### JSON schema basics
### Pagination & filtering
- limit/offset
- cursor-based
- filtering/sorting patterns

### Flask/FastAPI basics
- routing: path params + query params
- request/response JSON
- validation: FastAPI + Pydantic (Flask options briefly)
- OpenAPI/Swagger (FastAPI built-in)
- conceptual mini example: POST /chat or POST /classify

Deliver one structured explanation.
```

---

## ✅ Day 9 — Advanced API: Auth, Middleware, Errors, Async Endpoints, ORM Overview

```markdown
# Day 9 – Advanced API: Auth, Middleware, Errors, Async, ORM (GenAI Services)

You are an expert Senior AI Engineer interview coach.

Today is Day 9 of my 15-day compressed plan.

## Your task
1) Teach production API concerns for GenAI services.
2) Use examples like protected /chat, LLM failure handling, request tracing.
3) Best practices + pitfalls.
4) End with Interview Q&A (5–10) + concise answers.
5) Include small code/pseudocode snippets (commented).

## Topics – cover ALL
- Authentication & authorization
  - JWT basics
  - API keys vs OAuth2 (conceptual)
- Middleware & hooks
  - request/response logging
  - request ID correlation
  - latency measurement
- Error handling
  - custom exception handlers
  - standard error response format (error code, message, trace ID)
- Async endpoints (FastAPI focus)
- ORM & DB integration (overview)
  - sessions, transactions
  - simple CRUD via API endpoints

Deliver one structured explanation.
```

---

## ✅ Day 10 — ORM + SQL + Relational Modeling + DB Testing (End-to-End)

```markdown
# Day 10 – ORM + SQL + Relational Modeling + DB Testing (GenAI Apps)

You are an expert Senior AI Engineer interview coach with backend+data experience.

Today is Day 10 of my 15-day compressed plan.

## Your task
1) Explain ORMs + SQL modeling in GenAI apps (store conversations, usage logs, docs).
2) Show integration into an API (conceptually + small snippets).
3) Explain indexing, transactions, performance pitfalls (N+1).
4) Show DB testing patterns with pytest fixtures.
5) End with Interview Q&A (5–10) + concise answers.

## Topics – cover ALL
### ORM fundamentals
- models/entities, columns, relationships
- SQLAlchemy / SQLModel basics
  - defining models
  - CRUD
  - one-to-many relationships
  - N+1 and lazy loading (concept)
- transactions: commit/rollback patterns
- testing with DB
  - test DB / in-memory DB
  - pytest fixtures setup/teardown

### SQL & relational modeling
- schema design: tables, PK, FK
- normalization vs denormalization (trade-offs)
- core SQL: SELECT/INSERT/UPDATE/DELETE
- WHERE, GROUP BY, HAVING, ORDER BY
- JOINs: inner/left/right
- indexes: what/when/read-vs-write impact
- ACID basics
- example schema for multi-tenant GenAI app:
  - users, organizations, conversations, messages, documents
  - how it supports RAG + analytics

Deliver one structured explanation.
```

---

## ✅ Day 11 — NoSQL + Redis + Vector DBs + Caching (GenAI Data Layer)

```markdown
# Day 11 – NoSQL, Redis, Vector DBs & Caching (GenAI Systems)

You are an expert Senior AI Engineer interview coach.

Today is Day 11 of my 15-day compressed plan.

## Your task
1) Compare SQL vs NoSQL in GenAI systems.
2) Explain Redis + vector DBs with practical examples.
3) Explain caching patterns for LLMs and safety pitfalls.
4) End with Interview Q&A (5–10) + concise answers.

## Topics – cover ALL
- NoSQL concepts
  - document DBs (MongoDB)
  - flexible schema, collections, documents
- Redis
  - key–value store, TTL
  - use cases: caching LLM responses, rate limiting, locks
  - pattern: read-through cache
- Vector DB fundamentals
  - embeddings and vectors
  - similarity search (cosine/dot/euclidean – conceptual)
  - index types (HNSW, IVF, Flat – high level)
  - schema: id, text, embedding, metadata
  - tools overview: FAISS, Chroma, Qdrant, Pinecone
- Pitfalls
  - mismatched embedding models
  - missing metadata (tenant, doc type, time)

Deliver one structured explanation.
```

---

## ✅ Day 12 — ETL & Ingestion for RAG (Files/S3/DB/APIs/Web) + Data Quality & PII

```markdown
# Day 12 – ETL & Ingestion for RAG + Data Quality (GenAI Systems)

You are an expert Senior AI Engineer interview coach.

Today is Day 12 of my 15-day compressed plan.

## Your task
1) Explain ingestion/ETL pipelines end-to-end for RAG.
2) Show data flow into vector index.
3) Emphasize pitfalls: encoding, duplicates, missing metadata, PII risk.
4) Cover API ingestion + web scraping with ethics/legal basics.
5) End with Interview Q&A (5–10) + concise answers.
6) Provide a mini “pipeline blueprint” (read → clean → enrich → store → index).

## Topics – cover ALL
### ETL concepts
- batch vs streaming

### Data sources
- local filesystem: PDF, txt, CSV, JSON, Markdown
- object storage: S3/GCS/Azure Blob
- databases for bulk export
- API-based ingestion
  - pagination, rate limits, retries, backoff
- web scraping basics
  - requests + BeautifulSoup (or high-level libs)
  - robots.txt, legal/ethical notes

### Preprocessing
- cleaning text, removing boilerplate
- encoding issues
- simple language detection

### Metadata enrichment
- source, timestamp, tags, document type

### Data quality + governance
- duplicate detection
- PII detection & masking (concept)
- data lineage (source URL, timestamps)

Deliver one structured explanation.
```

---

## ✅ Day 13 — ML Fundamentals + Deep Learning + Transformers (Interview Overview)

```markdown
# Day 13 – ML Fundamentals + Deep Learning + Transformers (Interview-Focused)

You are an expert Senior AI Engineer interview coach.

Today is Day 13 of my 15-day compressed plan.

## Your task
1) Give interview-focused overview of ML basics + classical ML + math.
2) Add NLP/CV basics (high-level but correct).
3) Explain deep learning and transformers intuitively.
4) Link transformers to LLMs, embeddings, and RAG.
5) End with Interview Q&A (5–10) + concise answers.

## Topics – cover ALL
### ML basics
- supervised vs unsupervised vs RL (high-level)
- train/val/test splits
- overfitting & regularization (L2, dropout – intuition)

### Metrics
- accuracy, precision, recall, F1, ROC-AUC
- regression: MSE, MAE

### Classical algorithms (brief)
- linear/logistic regression, trees, random forests

### Math for ML
- vectors, matrices, dot product, cosine similarity
- gradients & backprop (intuition)
- probability: expectation, variance, conditional probability, Bayes rule

### NLP basics
- tokenization
- word embeddings (word2vec/GloVe idea)

### CV basics
- CNNs (very high-level)
- transfer learning

### Deep learning + transformers
- layers, activations, loss, optimization (SGD/Adam – conceptual)
- transformer architecture (high-level)
  - self-attention intuition (query/key/value)
  - positional encoding
- model types: encoder-only (BERT), decoder-only (GPT), encoder-decoder (T5)
- why transformers work well: parallelization, long-range dependencies

Deliver one structured explanation.
```

---

## ✅ Day 14 — LLM Fundamentals + Multimodal/Diffusion + Prompt Engineering & Guardrails

```markdown
# Day 14 – LLM Fundamentals + Multimodal + Prompt Engineering (Production Focus)

You are an expert Senior AI Engineer interview coach.

Today is Day 14 of my 15-day compressed plan.

## Your task
1) Explain LLM fundamentals: tokenization, training stages, inference controls.
2) Cover model families + context window + cost/latency trade-offs.
3) Explain multimodal LLMs + diffusion models + limitations/risks.
4) Teach prompt engineering patterns + guardrails + prompt testing/regression.
5) End with Interview Q&A (5–10) + concise answers.

## Topics – cover ALL
### LLM fundamentals
- tokenization: BPE, sentencepiece (concept)
- training pipeline: pre-training, fine-tuning, instruction tuning, RLHF/DPO (high-level)
- inference parameters: temperature, top-k, top-p, repetition penalty, max tokens
- context window: truncation, long-context limitations
- model families overview: GPT, LLaMA, Mistral, Gemma, Phi, etc.
- cost & latency: input vs output tokens; rough considerations

### Multi-modal + diffusion + limits
- multimodal: text+image input/output; vision encoder + LLM pattern
- diffusion: denoising diffusion intuition; text-to-image pipeline
- VAEs, GANs vs diffusion vs LLMs (high-level)
- limitations: hallucinations, bias, toxicity, copyright/safety
- evaluation: BLEU/ROUGE, LLM-as-judge, human rubrics

### Prompt engineering & guardrails
- system vs user vs assistant vs tool messages
- few-shot examples
- chain-of-thought (when and when not)
- ReAct style (reason + act)
- output format control (JSON, tables)
- guardrails via prompting: citations, refusal style, “I don’t know”
- prompt testing: test cases, regression suites
- anti-patterns: vague prompts, overlong prompts, brittle hacks

Deliver one structured explanation.
```

---

## ✅ Day 15 — Capstone Integration Day (RAG + Agents + Frameworks + Fine-tuning + LLMOps + Cloud/Infra + Security + UI + Monorepo)

```markdown
# Day 15 – Full-Stack GenAI System Design (End-to-End Interview Capstone)

You are an expert Senior AI Engineer, System Design Coach, and Cloud/DevOps Architect.

Today is Day 15 of my 15-day compressed plan.

## Your task
This is a FULL integration day. You must:
1) Provide an end-to-end mental model and reference architecture for a production GenAI app.
2) Cover all topics below with clear structure and trade-offs.
3) Include checklists + “what to say in interviews” bullets.
4) Include small snippets/pseudocode where helpful (commented).
5) End with Interview Q&A (10–15) including system design + behavioral.
6) Add a reusable project storytelling template (STAR + architecture narrative).

## Topics – cover ALL

### RAG fundamentals (end-to-end)
- ingestion/indexing pipeline
- query → retrieval → generation loop
- chunking strategies: fixed vs adaptive vs heading-based
- overlap and why it matters
- embeddings: choosing model; chunk → embed
- index schema: vector DB + metadata (tenant, doc type, time)
- simple RAG use-case design (internal policy docs / internal KB)

### Retrieval strategies + context assembly + evaluation
- query understanding: rewrite/expand with LLM
- retrieval: vector vs BM25 vs hybrid
- reranking (cross-encoder – conceptual)
- context assembly: how many chunks, ordering, truncation, filters
- hallucination mitigation: grounding, citations, abstain
- evaluation/tuning:
  - metrics: Recall@k, Precision@k, MRR (intuitive)
  - LLM-as-judge, human eval
  - tuning knobs: chunk size, k, reranker, model size, caching

### Agentic systems
- tools/function calling (when to call tools vs pure prompting)
- agent patterns: single tool agent; planner–executor–verifier
- memory: short-term vs long-term (KB/logs)
- failure handling: tool errors, malformed outputs, retries, fallbacks
- latency & cost: parallel calls, early exits, caching
- human-in-the-loop: approvals, escalation

### Frameworks comparison (framework-neutral first)
- nodes/edges/state/tools/orchestration mental model
- LangChain: chains, tools, agents, LCEL
- LangGraph: StateGraph, nodes/edges, loops/retries
- LlamaIndex: index types, query engines, retrievers
- AutoGen: multi-agent role specialization
- MCP & A2A/ADK style: tool servers/providers; graph orchestration idea
- N8N (no/low-code workflows + monitoring)

### Fine-tuning & evaluation
- training vs fine-tuning vs PEFT (LoRA/QLoRA – conceptual)
- data preparation: instruction format (system/input/output), cleaning, dedupe, PII removal
- scenarios: domain adaptation, style tuning, task-specific tuning
- evaluation: task metrics, benchmark-style, preference-based eval
- pitfalls: overfitting, catastrophic forgetting, noisy data

### Inference, deployment, LLMOps & monitoring
- inference options: API-based vs self-hosted (vLLM, TGI, Ollama – high-level)
- optimization: batching, caching (prompts/outputs), quantization (8/4-bit), streaming (SSE/WebSocket)
- deployment patterns: Docker, REST/gRPC, canary/rollback
- LLMOps:
  - logging prompts/responses with privacy considerations
  - metrics: latency, token usage, error rate
  - experiment tracking, model registry
  - golden test sets + behavioral regression tests

### Cloud + Kubernetes + scaling
- storage: S3/GCS/Blob
- compute: EC2/VMs
- managed K8s: EKS/GKE/AKS
- managed GenAI services overview: AWS Bedrock, Vertex AI, Azure OpenAI
- K8s basics: Deployment, Service, Ingress, ConfigMap, Secret, HPA
- scaling: scale out vs up; API Gateway; ALB/NLB concepts

### Security, privacy, safety & multi-tenant RAG
- AuthN/AuthZ, JWT, OAuth basics
- rate limiting, WAF/DDoS basics
- encryption in transit/at rest
- handling PII in logs & KB; RBAC
- prompt injection/jailbreaks; data exfiltration attacks
- output filtering/safety layers
- tenant isolation via metadata filters; separate indices/namespaces

### UI, productization & storytelling
- chat UI: conversation history, streaming responses
- citations/sources display
- feedback capture (thumbs up/down)
- Streamlit/Gradio quick demos; Open WebUI concept
- product thinking: POC vs MVP, success metrics (business + technical)
- reliability: retries, circuit breakers
- cost optimization: model choice, caching, batching, rate limits
- storytelling: Problem → Solution → HLD/LLD → Challenges → Impact → Learnings (STAR)

### Terraform/IaC + AWS GenAI infra + Helm/Jenkins/Ansible + Monorepo/DevEx
- IaC: imperative vs declarative; Terraform vs console/CloudFormation
- Terraform basics: resource/data/variable/output; init/plan/apply/destroy; providers
- state/backends: tfstate, S3 + DynamoDB lock (concept), drift risks
- modules & structure: root vs child; vpc/eks/rds; variables/locals/outputs
- environments: workspaces vs separate state folders; dev/stage/prod naming
- AWS stack wiring (concept + snippets):
  - VPC (public/private subnets, NAT/IGW), SG vs NACL brief
  - EKS (control plane vs nodes, node groups autoscaling, ALB ingress)
  - RDS Postgres (metadata/tenants/conversations)
  - ElastiCache Redis (cache, rate limit)
  - S3 (documents)
  - ECR (images)
  - IAM roles (EKS nodes access)
  - DNS & release-focused: Route53, ALB/Ingress, TLS/ACM DNS validation, traffic patterns
- Kubernetes/Helm:
  - chart structure, values.yaml, templates
  - helm install/upgrade/rollback, release naming
  - backend+frontend deployments, services, ingress, configmaps/secrets, HPA
- Jenkins CI/CD:
  - stages: test → build → push ECR → helm deploy
  - secrets handling in Jenkins
  - rollback strategies (helm rollback + image tags)
  - GenAI checks: golden tests + smoke tests
- Ansible:
  - where it fits vs Terraform
  - inventory/playbook basics, idempotence, roles, secrets (Vault high-level)
  - example use: Jenkins agents/ops box provisioning
- Monorepo + DevEx:
  - repo layout (backend/frontend/infra)
  - env/config strategy (.env vs secrets; helm values; terraform state separation)
  - branching & releases (PR → main; tags)
  - local dev workflow (mock services)
  - end-to-end pipeline story: git push → Jenkins → Docker → ECR → Helm → EKS

Deliver a single structured write-up with:
- a reference architecture (ASCII diagram),
- checklists,
- and interview Q&A + project storytelling template.
```

---
Here’s a **single “Master Prompt Generator”** you can paste anytime.
You only change **DAY=1..15** (and optionally MODE). It will output **only that day’s prompt** in a clean, copy-paste-ready form.

````markdown
# MASTER PROMPT GENERATOR — 15-Day GenAI/LLM Interview Prep
# Usage:
# 1) Set DAY to 1..15
# 2) (Optional) Set MODE to "MAP_THEN_DEEPDIVE" (recommended) or "FULL_NOTES"
# 3) Send this prompt. You must output ONLY the generated Day prompt (no extra commentary).

DAY = 1
MODE = "MAP_THEN_DEEPDIVE"   # or "FULL_NOTES"
PARTS_RANGE = "7–9"
STUDY_TIME_PER_PART = "20–40 minutes"
ROLE = "Senior AI Engineer interview coach"
GOAL = "Senior AI Engineer (GenAI/RAG) interviews: strong fundamentals + system design + production readiness"

# =========================
# RULES (STRICT)
# =========================
- You are my {ROLE}.
- I am following a 15-day compressed plan derived from an original 37-day plan.
- Do NOT add new topics outside the day’s scope.
- Do NOT remove any sub-topic listed for that day.
- Keep the day prompt interview-focused and production-oriented (GenAI backend context).
- If MODE="MAP_THEN_DEEPDIVE":
  - Step 1: Create a Table of Contents with EXACTLY {PARTS_RANGE} parts.
  - For each part include:
    - Part title
    - What it covers (3–6 bullets)
    - Why it matters in interviews (2–4 bullets)
    - What I must be able to explain (2–4 bullets)
    - Key terms (5–10)
    - Mini-checklist (5–8 “I can explain…”)
  - STOP and ask: “Which part number should I start with?”
  - If any part is too large, automatically split into “Part XA / XB” and deliver only XA first, then ask if I want XB.
- If MODE="FULL_NOTES":
  - Produce one structured explanation with:
    - clear headings + bullets
    - 2–3 real-world examples
    - best practices + pitfalls
    - Interview Q&A (5–10) with concise strong answers
    - code (if any) must be beginner-friendly with comments + tricky parts highlighted

- OUTPUT FORMAT:
  - You must output ONLY ONE thing: the generated prompt for Day {DAY}
  - Wrap it inside one markdown code block (```markdown ... ```). Nothing else.

# =========================
# DAY MAP (15 DAYS)
# =========================

DAY_1_TITLE = "Python Core + Environment + Logging/Error Basics"
DAY_1_TOPICS = [
  "Python fundamentals: int/float/str/bool; list/dict/set/tuple; slicing; list/dict comprehensions",
  "Functions & modules: defining functions; *args/**kwargs; modules/packages/imports (absolute vs relative)",
  "Environment & tooling: venv, pyenv, uv; basic project layout; .env + python-dotenv",
  "Logging & basic error handling: logging module; try/except/finally; raise vs return errors (API services)"
]

DAY_2_TITLE = "Python OOP + Dataclasses + Design Exercise"
DAY_2_TOPICS = [
  "Core OOP: classes/objects; encapsulation/abstraction; inheritance/polymorphism; composition vs inheritance",
  "Python OOP features: __init__; instance vs class variables; @staticmethod/@classmethod; @property; @dataclass use cases",
  "Dunder methods: __repr__/__str__/__len__/__eq__ and why useful",
  "Design exercise: ModelProvider hierarchy; RagPipeline responsibilities separation"
]

DAY_3_TITLE = "Advanced Python + Testing/Mocks + Clean Architecture & Patterns"
DAY_3_TOPICS = [
  "Typing: List/Dict/Optional/Union/TypedDict; why typing helps large AI systems; mypy (high-level)",
  "Validation: Pydantic basics; API schemas; tool I/O; config objects",
  "Errors & logging: custom exceptions; levels; structured logs; correlation IDs",
  "Testing: pytest fixtures; mocking HTTP/DB/LLM APIs",
  "Design patterns + clean architecture: SOLID; Factory/Strategy/Adapter/Decorator/Facade; layered architecture; example project structure"
]

DAY_4_TITLE = "Async & Concurrency in Python for GenAI Backends"
DAY_4_TOPICS = [
  "Sync vs async I/O: when async matters in GenAI services",
  "async/await + asyncio: event loop; tasks; asyncio.gather",
  "Concurrency models: threads vs processes vs async; concurrent.futures basics",
  "Pitfalls: blocking I/O in async; race conditions; debugging/observability for async services"
]

DAY_5_TITLE = "DSA Core I: Arrays, Strings, Hashing & Prefix Sums"
DAY_5_TOPICS = [
  "Complexity basics: Big-O time/space quick refresher",
  "Arrays/strings: traversal; subarrays/substrings; prefix sums (subarray sum queries)",
  "Hashing: frequency counting; two-sum pattern; duplicates; anagrams"
]

DAY_6_TITLE = "DSA Core II: Two Pointers, Sliding Window, Stacks & Queues"
DAY_6_TOPICS = [
  "Two pointers: sorted arrays; inward pointers; move left/right patterns",
  "Sliding window: fixed-size; variable-size (longest/shortest with property)",
  "Stacks/queues: use cases; balanced parentheses; monotonic stack concept; next greater element concept"
]

DAY_7_TITLE = "Trees, Graphs, DP Intro + Workflow DAG Linkage + Week Review"
DAY_7_TOPICS = [
  "Trees/graphs: DFS/BFS concept + simple code; traversals (pre/in/post)",
  "DP basics: 0/1 knapsack intuition; top-down memo vs bottom-up",
  "Real-world linkage: dependency graphs; scheduling; pipeline DAGs (Airflow/LangGraph conceptual)",
  "Short review checklist for Days 1–6"
]

DAY_8_TITLE = "HTTP + REST API Design + Flask/FastAPI Basics"
DAY_8_TOPICS = [
  "HTTP: methods; status codes; headers; query/path params; body",
  "REST: resource modeling; idempotency; versioning (/v1,/v2)",
  "JSON schema basics; pagination/filtering: limit/offset + cursor",
  "AI/ML endpoints: /chat /embed /predict /health",
  "Flask vs FastAPI trade-offs; routing; request/response; validation; OpenAPI/Swagger; small illustrative endpoint"
]

DAY_9_TITLE = "Advanced API: Auth, Middleware, Errors, Async Endpoints, ORM Overview"
DAY_9_TOPICS = [
  "AuthN/AuthZ: JWT basics; API keys vs OAuth2 (conceptual)",
  "Middleware/hooks: request logging; request-id correlation; latency metrics",
  "Error handling: custom exception handlers; standard error format (code/message/traceId)",
  "Async endpoints (FastAPI focus)",
  "ORM/DB integration overview: sessions; transactions; basic CRUD via API"
]

DAY_10_TITLE = "ORM + SQL + Relational Modeling + DB Testing"
DAY_10_TOPICS = [
  "ORM fundamentals: models/entities/columns/relationships",
  "SQLAlchemy/SQLModel: defining models; CRUD; one-to-many; N+1 + lazy loading concept",
  "Transactions: commit/rollback patterns",
  "Testing with DB: test DB/in-memory; pytest fixtures setup/teardown",
  "SQL + modeling: PK/FK; normalization vs denormalization; core SQL; joins; indexes; ACID",
  "Example schema: users/organizations/conversations/messages/documents supporting RAG + analytics"
]

DAY_11_TITLE = "NoSQL + Redis + Vector DBs + Caching"
DAY_11_TOPICS = [
  "SQL vs NoSQL fit in GenAI systems",
  "MongoDB concepts: documents/collections/flexible schema",
  "Redis: TTL; caching LLM responses; rate limiting; locks; read-through cache",
  "Vector DB: embeddings; similarity search; index types (HNSW/IVF/Flat); schema (id/text/embedding/metadata); tools (FAISS/Chroma/Qdrant/Pinecone)",
  "Pitfalls: mismatched embedding models; missing metadata (tenant/doc type/time)"
]

DAY_12_TITLE = "ETL & Ingestion for RAG + Data Quality + PII + API/Web"
DAY_12_TOPICS = [
  "ETL concepts: batch vs streaming",
  "Data sources: PDFs/txt/csv/json/md; S3/GCS/Blob; DB exports",
  "API ingestion: pagination; rate limits; retries/backoff",
  "Web scraping: requests+BeautifulSoup; robots.txt; legal/ethical",
  "Preprocessing: cleaning; boilerplate; encoding issues; simple language detection",
  "Metadata enrichment: source/timestamp/tags/doc type",
  "Data quality/governance: dedupe; PII detection/masking concept; data lineage"
]

DAY_13_TITLE = "ML Fundamentals + Deep Learning + Transformers (Interview Overview)"
DAY_13_TOPICS = [
  "ML basics: supervised/unsupervised/RL; splits; overfitting; regularization (L2/dropout intuition)",
  "Metrics: accuracy/precision/recall/F1/ROC-AUC; regression MSE/MAE",
  "Classical ML: linear/logistic regression; trees; random forests",
  "Math: vectors/matrices; dot product/cosine; gradients/backprop intuition; probability + Bayes",
  "NLP: tokenization; word embeddings (word2vec/GloVe idea)",
  "CV: CNN high-level; transfer learning",
  "Deep learning: layers/activations/loss; SGD/Adam concept",
  "Transformers: self-attention (QKV intuition); positional encoding; encoder-only vs decoder-only vs enc-dec; why transformers work"
]

DAY_14_TITLE = "LLM Fundamentals + Multimodal/Diffusion + Prompt Engineering & Guardrails"
DAY_14_TOPICS = [
  "LLM fundamentals: tokenization (BPE/sentencepiece); training stages (pretrain/finetune/instruction/RLHF-DPO high-level)",
  "Inference params: temperature/top-k/top-p/repetition/max tokens; context window limits",
  "Model families: GPT/LLaMA/Mistral/Gemma/Phi overview; cost/latency trade-offs (input vs output tokens)",
  "Multimodal LLMs: vision encoder + LLM pattern; use cases",
  "Diffusion: denoising intuition; text-to-image pipeline; VAEs/GANs vs diffusion vs LLMs (high-level)",
  "Limitations/safety: hallucinations/bias/toxicity/copyright; evaluation: BLEU/ROUGE, LLM-as-judge, human rubrics",
  "Prompt engineering: system/user/assistant/tool; few-shot; CoT when/when-not; ReAct; output format control",
  "Guardrails + testing: citations/refusal/I-don’t-know; prompt test cases; regression suites; anti-patterns"
]

DAY_15_TITLE = "Capstone Integration: RAG + Agents + Frameworks + Fine-tuning + LLMOps + Cloud/Infra + Security + UI + Monorepo"
DAY_15_TOPICS = [
  "RAG: ingestion/indexing; query→retrieve→generate; chunking strategies; overlap; embeddings; index schema + metadata; internal KB use case",
  "Retrieval & eval: rewrite/expand; vector vs BM25 vs hybrid; reranking; context assembly; hallucination mitigation; metrics Recall@k/Precision@k/MRR; tuning knobs",
  "Agents: tools/function calling; planner-executor-verifier; memory; failure handling; cost/latency; HITL approvals",
  "Frameworks: neutral mental model; LangChain; LangGraph; LlamaIndex; AutoGen; MCP & A2A/ADK; n8n overview",
  "Fine-tuning: training vs finetune vs PEFT (LoRA/QLoRA); data prep; scenarios; eval; pitfalls",
  "Inference/Deployment/LLMOps: API vs self-hosted (vLLM/TGI/Ollama); batching/caching/quantization/streaming; canary/rollback; logging & privacy; metrics; golden tests; model registry",
  "Cloud/K8s: storage/compute/managed K8s; Bedrock/Vertex/Azure OpenAI; Deploy/Service/Ingress/ConfigMap/Secret/HPA; scaling patterns; gateways/LB",
  "Security/Privacy/Safety: Auth; rate limits; WAF/DDoS; encryption; PII; RBAC; prompt injection; exfiltration; tenant isolation (namespaces/metadata filters)",
  "UI/Productization/Storytelling: chat UI; streaming; citations; feedback; Streamlit/Gradio/OpenWebUI concept; POC vs MVP; reliability; cost; STAR storytelling",
  "Terraform/AWS infra/Helm/Jenkins/Ansible/Monorepo: IaC basics; state/backends; modules; env strategy; VPC/EKS/RDS/Redis/S3/ECR/IAM; Route53+ACM; Helm charts; Jenkins pipeline; Ansible role; DevEx+branching+release story"
]

# =========================
# GENERATION INSTRUCTIONS
# =========================
- Select the correct DAY_{DAY}_TITLE and DAY_{DAY}_TOPICS.
- Create the final Day prompt using this structure:

  Title: "# Day {DAY} – <DAY_TITLE> (Senior AI Engineer Interview Prep)"

  Then:
  - Role reminder + goal
  - "Today’s topics – cover ALL of these" list (verbatim, expanded as bullets)
  - If MODE="MAP_THEN_DEEPDIVE": include Step 1 (TOC rules) + Step 2 (Deep Dive rules) + stopping condition.
  - If MODE="FULL_NOTES": include the full-notes instruction set.

- IMPORTANT: Output ONLY the final Day prompt inside one ```markdown code block``` and nothing else.

NOW GENERATE THE PROMPT FOR Day {DAY}.
````

### How you’ll use it (simple)

* Every day in a **new chat**:

  1. Set `DAY = X`
  2. Keep `MODE = "MAP_THEN_DEEPDIVE"` (so notes don’t become huge)
  3. Paste → it outputs that day’s **study prompt**
  4. Copy that output and run it in the same chat (or a fresh one)
